import streamlit as st
import re
import pandas as pd
import csv
from pathlib import Path
from datetime import datetime
from difflib import get_close_matches
import os

# Configuraci√≥n de variables desde secrets.toml
SMTP_SERVER = st.secrets["smtp_server"]
SMTP_PORT = st.secrets["smtp_port"]
EMAIL_USER = st.secrets["email_user"]
EMAIL_PASSWORD = st.secrets["email_password"]
NOTIFICATION_EMAIL = st.secrets["notification_email"]
CSV_PRODUCTOS_FILE = st.secrets.get("remote_productos")
CSV_MANUAL_FILE = st.secrets.get("remote_manual")
CSV_TESIS_FILE = st.secrets.get("remote_tesis")
CSV_LIBROS_FILE = st.secrets.get("remote_libros")
CSV_CAPITULOS_FILE = st.secrets.get("remote_capitulos")
REMOTE_HOST = st.secrets["remote_host"]
REMOTE_USER = st.secrets["remote_user"]
REMOTE_PASSWORD = st.secrets["remote_password"]
REMOTE_PORT = st.secrets["remote_port"]
REMOTE_DIR = st.secrets["remote_dir"]

os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

KEYWORD_CATEGORIES = {
    "Accidente Cerebrovascular": ["accidente cerebrovascular", "acv", "ictus", "stroke"],
    "Alzheimer": ["alzheimer", "demencia", "enfermedad neurodegenerativa"],
    "Arritmias": [
        "arritmia", "fibrilaci√≥n auricular", "fa", "flutter auricular", 
        "taquicardia ventricular", "tv", "fibrilaci√≥n ventricular", "fv",
        "bradicardia", "bloqueo auriculoventricular", "s√≠ndrome de brugada", 
        "s√≠ndrome de qt largo", "marcapasos", "desfibrilador autom√°tico"
    ],
    "Bioinform√°tica": ["bioinform√°tica", "gen√≥mica computacional", "an√°lisis de secuencias", "biolog√≠a de sistemas"],
    "Bioqu√≠mica": ["bioqu√≠mica", "metabolismo", "enzimas", "rutas metab√≥licas"],
    "Biolog√≠a Molecular": ["adn", "arn", "transcripci√≥n", "replicaci√≥n"],
    "Biomarcadores Card√≠acos": [
        "troponina", "nt-probnp", "bnp", "ck-mb", "lactato deshidrogenasa", 
        "mioglobina", "p√©ptidos natriur√©ticos"
    ],
    "Biotecnolog√≠a": ["biotecnolog√≠a", "terapia g√©nica", "crispr", "organismos modificados gen√©ticamente"],
    "C√°ncer de Mama": ["c√°ncer de mama", "tumor mamario", "neoplasia mamaria"],
    "Cardiolog√≠a Pedi√°trica": [
        "cardiopat√≠a cong√©nita", "comunicaci√≥n interauricular", "cia", 
        "comunicaci√≥n interventricular", "civ", "tetralog√≠a de fallot", 
        "transposici√≥n grandes vasos", "ductus arterioso persistente"
    ],
    "Cardiomiopat√≠as": [
        "cardiomiopat√≠a", "miocardiopat√≠a", "cardiomiopat√≠a hipertr√≥fica", "hcm", 
        "cardiomiopat√≠a dilatada", "dcm", "cardiomiopat√≠a restrictiva", 
        "displasia arritmog√©nica", "miocardiopat√≠a no compactada", "amiloidosis card√≠aca"
    ],
    "Endocrinolog√≠a": ["diabetes", "tiroides", "hormonas", "metabolismo"],
    "Enfermedad Vascular Perif√©rica": [
        "enfermedad arterial perif√©rica", "eap", "claudicaci√≥n intermitente", 
        "√≠ndice tobillo-brazo", "isquemia cr√≠tica", "arteriopat√≠a obliterante"
    ],
    "Epidemiolog√≠a": ["epidemiolog√≠a", "estudios poblacionales", "incidencia", "prevalencia"],
    "Epilepsia": ["epilepsia", "crisis epil√©ptica", "convulsiones"],
    "Farmacolog√≠a": ["farmacolog√≠a", "f√°rmacos", "dosis-respuesta", "toxicidad"],
    "Gastroenterolog√≠a": ["colon", "h√≠gado", "p√°ncreas", "enfermedad inflamatoria intestinal"],
    "Gen√©tica": ["gen√©tica", "mutaciones", "genoma humano", "s√≠ndromes gen√©ticos"],
    "Hipertensi√≥n y Riesgo Cardiovascular": [
        "hipertensi√≥n arterial", "hta", "hipertensi√≥n pulmonar", 
        "crisis hipertensiva", "mapa", "monitorizaci√≥n ambulatoria", 
        "riesgo cardiovascular", "score framingham", "ascvd"
    ],
    "Inmunolog√≠a": ["autoinmunidad", "inmunodeficiencia", "alergias", "linfocitos"],
    "Inmunoterapia": ["inmunoterapia", "terapia car-t", "checkpoint inmunol√≥gico"],
    "Insuficiencia Card√≠aca": [
        "insuficiencia card√≠aca", "ic", "fallo card√≠aco", "disfunci√≥n ventricular", 
        "icfe", "icfd", "fracci√≥n de eyecci√≥n reducida", "fracci√≥n de eyecci√≥n preservada",
        "nyha clase ii", "nyha clase iii", "edema pulmonar", "congesti√≥n venosa"
    ],
    "Investigaci√≥n Cl√≠nica": ["ensayo cl√≠nico", "randomizado", "estudio de cohorte", "fase iii"],
    "Leucemia": ["leucemia", "leucemias agudas", "leucemia mieloide"],
    "Microbiolog√≠a": ["microbiolog√≠a", "bacterias", "virus", "antimicrobianos"],
    "Nefrolog√≠a": ["insuficiencia renal", "glomerulonefritis", "di√°lisis"],
    "Neumolog√≠a": ["asma", "epoc", "fibrosis pulmonar", "s√≠ndrome de apnea del sue√±o"],
    "Neurociencia": ["neurociencia", "plasticidad neuronal", "sinapsis", "neurodegeneraci√≥n"],
    "Oncolog√≠a Molecular": ["oncolog√≠a molecular", "mutaciones tumorales", "biomarcadores c√°ncer"],
    "Procedimientos Cardiol√≥gicos": [
        "cateterismo card√≠aco", "angioplastia", "stent coronario", 
        "bypass coronario", "cabg", "ecocardiograma", "eco stress", 
        "resonancia card√≠aca", "prueba de esfuerzo", "holter"
    ],
    "S√≠ndrome Coronario Agudo": [
        "s√≠ndrome coronario agudo", "sca", "infarto agudo de miocardio", "iam", 
        "iamcest", "iamnest", "angina inestable", "troponina elevada", 
        "oclusi√≥n coronaria", "elevaci√≥n st", "depresi√≥n st"
    ],
    "Valvulopat√≠as": [
        "valvulopat√≠a", "estenosis a√≥rtica", "insuficiencia a√≥rtica", 
        "estenosis mitral", "insuficiencia mitral", "prolapso mitral", 
        "tavi", "taavi", "anillo mitral", "reemplazo valvular"
    ],
}

def extract_keywords(title):
    if not title:
        return []
    found_keywords = set()
    title_lower = title.lower()
    for category, keywords in KEYWORD_CATEGORIES.items():
        for keyword in keywords:
            if keyword in title_lower:
                found_keywords.add(category)
                break
    return sorted(found_keywords)

def determinar_grupo(jif5years):
    if pd.isna(jif5years):
        return "Grupo 1 (sin factor de impacto)"
    try:
        jif = float(jif5years)
        if jif <= 0.9:
            return "Grupo 2 (FI ‚â§ 0.9)"
        elif jif <= 2.99:
            return "Grupo 3 (FI 1-2.99)"
        elif jif <= 5.99:
            return "Grupo 4 (FI 3-5.99)"
        elif jif <= 8.99:
            return "Grupo 5 (FI 6-8.99)"
        elif jif <= 11.99:
            return "Grupo 6 (FI 9-11.99)"
        else:
            return "Grupo 7 (FI ‚â• 12)"
    except ValueError:
        return "Grupo 1 (sin factor de impacto)"

def buscar_grupo_revista(nombre_revista, file_path='CopyofImpactFactor2024.xlsx'):
    try:
        df = pd.read_excel(file_path, sheet_name='2024ÊúÄÊñ∞ÂÆåÊï¥ÁâàIF')
        df['Name_lower'] = df['Name'].str.lower()
        df['Abbr_Name_lower'] = df['Abbr Name'].str.lower()
        df['JIF5Years'] = pd.to_numeric(df['JIF5Years'], errors='coerce')

        exact_match = df[(df['Name_lower'] == nombre_revista.lower()) |
                         (df['Abbr_Name_lower'] == nombre_revista.lower())]
        if not exact_match.empty:
            return determinar_grupo(exact_match.iloc[0]['JIF5Years'])

        closest_match = get_close_matches(
            nombre_revista.lower(),
            df['Name_lower'].tolist() + df['Abbr_Name_lower'].tolist(),
            n=1, cutoff=0.6
        )
        if closest_match:
            match_row = df[(df['Name_lower'] == closest_match[0]) |
                          (df['Abbr_Name_lower'] == closest_match[0])].iloc[0]
            return determinar_grupo(match_row['JIF5Years'])

        return "Grupo no determinado"
    except Exception as e:
        st.warning(f"Error al buscar grupo: {str(e)}")
        return "Grupo no determinado"

def parse_nbib_file(content: str) -> dict:
    data = {
        'corresponding_author': '',
        'coauthors': '',
        'article_title': '',
        'year': '',
        'pub_date': '',
        'volume': '',
        'number': '',
        'pages': '',
        'journal_full': '',
        'journal_abbrev': '',
        'doi': '',
        'jcr_group': '',
        'pmid': '',
        'investigator_name': '',
        'economic_number': '',
        'participation_key': '',
        'selected_keywords': []
    }

    def extract_field(pattern, multi_line=False):
        nonlocal content
        flags = re.DOTALL if multi_line else 0
        match = re.search(pattern, content, flags)
        return match.group(1).strip() if match else ''

    try:
        data['pmid'] = extract_field(r'PMID-\s+(\d+)')
        authors = re.findall(r'FAU\s+-\s+(.*?)\n', content)
        if authors:
            data['corresponding_author'] = authors[0].strip()
            data['coauthors'] = "; ".join(a.strip() for a in authors[1:])
        data['article_title'] = extract_field(r'TI\s+-\s+(.*?)(?:\n[A-Z]{2}\s+-|$)', True)

        pub_date_match = re.search(r'DP\s+-\s+(\d{4}\s+[A-Za-z]{3}\s+\d{1,2})', content)
        if pub_date_match:
            try:
                date_obj = datetime.strptime(pub_date_match.group(1), '%Y %b %d')
                data['pub_date'] = date_obj.strftime('%Y-%m-%d')
                data['year'] = date_obj.strftime('%Y')
            except:
                data['pub_date'] = pub_date_match.group(1)
                data['year'] = pub_date_match.group(1).split()[0]
        else:
            data['year'] = extract_field(r'DP\s+-\s+(\d{4})')
            data['pub_date'] = data['year']

        # Solicitar al usuario que ingrese la fecha completa en formato YYYY-MM-DD
        st.subheader("üìÖ Fecha de publicaci√≥n")
        default_date = f"{data['year']}-01-01" if data['year'] else ""
        pub_date = st.text_input("Ingrese la fecha de publicaci√≥n (YYYY-MM-DD):",
                               value=default_date,
                               help="Formato: A√±o-Mes-D√≠a (ej. 2023-05-15)")

        # Validar el formato de fecha
        try:
            datetime.strptime(pub_date, '%Y-%m-%d')
            data['pub_date'] = pub_date
        except ValueError:
            st.error("Formato de fecha inv√°lido. Por favor use YYYY-MM-DD")
            return None

        data['volume'] = extract_field(r'VI\s+-\s+(\S+)')
        data['number'] = extract_field(r'IP\s+-\s+(\S+)')
        data['pages'] = extract_field(r'PG\s+-\s+(\S+)')
        data['journal_full'] = extract_field(r'JT\s+-\s+(.*?)\n')
        data['journal_abbrev'] = extract_field(r'TA\s+-\s+(.*?)\n')
        if data['journal_full'] or data['journal_abbrev']:
            data['jcr_group'] = buscar_grupo_revista(data['journal_full'] or data['journal_abbrev'])

        doi_match = re.search(r'DO\s+-\s+(.*?)\n', content) or \
                   re.search(r'(?:LID|AID)\s+-\s+(.*?doi\.org/.*?)\s', content) or \
                   re.search(r'(?:LID|AID)\s+-\s+(10\.\S+)', content)
        if doi_match:
            data['doi'] = doi_match.group(1).strip()

    except Exception as e:
        st.error(f"Error al procesar archivo .nbib: {str(e)}")

    return data

def save_to_csv(data: dict, filename=CSV_PRODUCTOS_FILE):
    try:
        # Crear DataFrame con los datos nuevos
        df_new = pd.DataFrame([data])
        
        # Limpiar los datos (eliminar saltos de l√≠nea y espacios extra)
        for col in df_new.columns:
            if df_new[col].dtype == object:
                df_new[col] = df_new[col].astype(str).str.replace(r'\r\n|\n|\r', ' ', regex=True).str.replace(r'\s+', ' ', regex=True).str.strip()

        # Definir las columnas esperadas en el orden deseado
        columns = [
            'economic_number', 'participation_key', 'investigator_name',
            'corresponding_author', 'coauthors', 'article_title', 'year',
            'pub_date', 'volume', 'number', 'pages', 'journal_full',
            'journal_abbrev', 'doi', 'jcr_group', 'pmid', 'selected_keywords'
        ]

        # Si el archivo no existe, crear uno nuevo con las columnas en el orden correcto
        if not Path(filename).exists():
            df_new[columns].to_csv(filename, index=False, encoding='utf-8-sig', 
                                 lineterminator='\n', quoting=csv.QUOTE_ALL)
            return True

        # Si el archivo existe, leerlo y concatenar los datos nuevos
        df_existing = pd.read_csv(filename, encoding='utf-8-sig', dtype={'economic_number': str})
        df_existing['economic_number'] = df_existing['economic_number'].astype(str).str.strip()
        
        # Combinar los DataFrames
        df_combined = pd.concat([df_existing, df_new], ignore_index=True)
        
        # Guardar el DataFrame combinado
        df_combined[columns].to_csv(filename, index=False, encoding='utf-8-sig', 
                                  lineterminator='\n', quoting=csv.QUOTE_ALL)
        return True
    except Exception as e:
        st.error(f"Error al guardar en CSV: {str(e)}")
        return False

def highlight_author(author: str, investigator_name: str) -> str:
    if investigator_name and investigator_name.lower() == author.lower():
        return f"<span style='background-color: #90EE90;'>{author}</span>"
    return author

def display_author_info(data, investigator_name):
    st.markdown("**Autores**")
    st.markdown(f"üìå Correspondencia: {highlight_author(data['corresponding_author'], investigator_name)}", unsafe_allow_html=True)
    if data['coauthors']:
        st.markdown("üë• Coautores:")
        for author in data['coauthors'].split("; "):
            st.markdown(f"- {highlight_author(author, investigator_name)}", unsafe_allow_html=True)

def display_publication_info(data):
    st.markdown("**Detalles de publicaci√≥n**")
    st.write(f"üìÖ A√±o: {data['year']}")
    st.write(f"**üìÖ Fecha de publicaci√≥n:**  \n`{data['pub_date']}`")
    st.write(f"üìö Vol/N√∫m: {data['volume']}/{data['number']}")
    st.write(f"üîñ P√°ginas: {data['pages']}")
    st.write(f"üåê DOI: {data['doi'] or 'No disponible'}")

def main():
    # Configuraci√≥n de la p√°gina con logo y t√≠tulo
    st.set_page_config(
        page_title="Art√≠culos en PubMed",
        page_icon="üìä",
        layout="centered"
    )

    # Logo y t√≠tulo
    col1, col2 = st.columns([1, 3])
    with col1:
        st.image("escudo_COLOR.jpg", width=80)
    with col2:
        st.title("üìä Art√≠culos en PubMed")
    
    economic_input = st.text_input("üî¢ N√∫mero econ√≥mico del investigador:")
    economic_number = str(economic_input).strip()
    
    if not economic_number or not economic_number.isdigit():
        st.warning("Por favor ingrese un n√∫mero econ√≥mico v√°lido (solo d√≠gitos)")
        return

    st.markdown(f"**üßæ N√∫mero econ√≥mico ingresado:** `{economic_number}`")

    # Verificar si el archivo existe, pero no mostrar error si no existe
    if Path(CSV_PRODUCTOS_FILE).exists():
        try:
            productos_df = pd.read_csv(CSV_PRODUCTOS_FILE, encoding='utf-8-sig', dtype={'economic_number': str})
            productos_df['economic_number'] = productos_df['economic_number'].astype(str).str.strip()

            if st.checkbox("üìÇ Mostrar todos los registros del CSV"):
                st.dataframe(productos_df, use_container_width=True)

            filtered_records = productos_df[productos_df['economic_number'].astype(str).str.strip() == economic_number]

            if not filtered_records.empty:
                st.subheader(f"üìã Registros existentes para el n√∫mero econ√≥mico {economic_number}")
                cols_to_show = ['economic_number', 'participation_key', 'investigator_name', 'article_title', 'journal_full']
                st.dataframe(filtered_records[cols_to_show], hide_index=True, use_container_width=True)
            else:
                st.info(f"No se encontraron registros para el n√∫mero econ√≥mico {economic_number}")
            
            if st.radio("¬øDesea a√±adir un nuevo registro?", ["No", "S√≠"], index=0) == "No":
                st.success("Proceso finalizado. Puede cerrar la aplicaci√≥n.")
                return

        except Exception as e:
            st.error(f"Error al leer {CSV_PRODUCTOS_FILE}: {str(e)}")
            return
    else:
        st.info(f"No se encontr√≥ un archivo {CSV_PRODUCTOS_FILE} existente. Se crear√° uno nuevo al guardar el primer registro.")

    st.subheader("üì§ Subir art√≠culo cient√≠fico")
    st.markdown("""
‚ÑπÔ∏è **Nota:**  
1. **Busque en otra ventana el art√≠culo** en [PubMed](https://pubmed.ncbi.nlm.nih.gov/)               
2. **Localice el bot√≥n 'Cite'** en la p√°gina del art√≠culo  
3. **Haga clic en 'Download .nbib'**  
4. **Suba el archivo descargado** en el selector a continuaci√≥n  
    """)
    uploaded_file = st.file_uploader("Seleccione archivo .nbib", type=".nbib")
    if not uploaded_file:
        return
    try:
        content = uploaded_file.read().decode("utf-8")
    except Exception as e:
        st.error(f"Error al leer archivo: {str(e)}")
        return

    with st.expander("üîç Ver contenido original"):
        st.code(content)

    data = parse_nbib_file(content)

    st.subheader("üìù Informaci√≥n extra√≠da")
    st.markdown("### üìÑ T√≠tulo del art√≠culo")
    st.info(data['article_title'])

    st.subheader("üîë Selecci√≥n de palabras clave (Elija 3)")
    suggested_keywords = extract_keywords(data['article_title'])
    all_categories = list(KEYWORD_CATEGORIES.keys())
    selected_categories = st.multiselect(
        "Seleccione categor√≠as relevantes:",
        options=all_categories,
        default=suggested_keywords[:3],
        max_selections=3
    )
    if len(selected_categories) < 3:
        st.warning(f"Por favor seleccione al menos 3 palabras clave (seleccionadas: {len(selected_categories)})")

    data['selected_keywords'] = selected_categories[:3]

    if data['selected_keywords']:
        st.markdown("**Palabras clave seleccionadas:**")
        st.info(", ".join(data['selected_keywords']))

    cols = st.columns(2)
    with cols[0]:
        display_author_info(data, "")
    with cols[1]:
        display_publication_info(data)

    st.markdown("**Revista**")
    st.write(f"üèõÔ∏è Nombre: {data['journal_full']}")
    st.write(f"üè∑Ô∏è Abreviatura: {data['journal_abbrev']}")
    st.write(f"üèÜ Grupo JCR: {data['jcr_group']}")

    st.subheader("üë§ Verificaci√≥n de autor√≠a")
    authors_list = []
    if data['corresponding_author']:
        authors_list.append(data['corresponding_author'])
    if data['coauthors']:
        authors_list.extend(data['coauthors'].split("; "))

    if not authors_list:
        st.error("No se encontraron autores en el art√≠culo")
        return

    investigator_name = st.selectbox("Seleccione su nombre como aparece en la publicaci√≥n:", authors_list)
    st.markdown(f"**Selecci√≥n actual:** {highlight_author(investigator_name, investigator_name)}", unsafe_allow_html=True)

    data['investigator_name'] = investigator_name
    data['economic_number'] = economic_number
    data['participation_key'] = "CA" if investigator_name == data['corresponding_author'] else f"{authors_list.index(investigator_name)}C"

    st.markdown("---")
    st.markdown("**Resumen de identificaci√≥n**")
    cols = st.columns(2)
    with cols[0]:
        st.markdown(f"**üî¢ N√∫mero econ√≥mico:**  \n`{economic_number}`")
    with cols[1]:
        st.markdown(f"**üîë Clave participaci√≥n:**  \n`{data['participation_key']}`")
    st.markdown(f"**üë§ Nombre investigador:**  \n`{investigator_name}`")
    st.markdown("---")

    if st.button("üíæ Guardar registro", type="primary"):
        if save_to_csv(data):
            st.balloons()
            st.success("‚úÖ Registro guardado exitosamente!")
            st.subheader("üìÑ Registro completo capturado")
            
            cols = st.columns(2)
            with cols[0]:
                st.markdown(f"**üî¢ N√∫mero econ√≥mico:**  \n`{data['economic_number']}`")
                st.markdown(f"**üë§ Investigador:**  \n`{data['investigator_name']}`")
            with cols[1]:
                st.markdown(f"**üîë Clave participaci√≥n:**  \n`{data['participation_key']}`")
                st.markdown(f"**üìÖ A√±o publicaci√≥n:**  \n`{data['year']}`")

            
            st.markdown("**üìÑ Datos completos:**")
            st.json(data)

if __name__ == "__main__":
    main()
