import streamlit as st
import pandas as pd
import io
from datetime import datetime
import calendar
import paramiko
import time
import os
import logging
from pathlib import Path
from PIL import Image

# Configuraci√≥n de logging
logging.basicConfig(
    filename='tesis.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# ====================
# CATEGOR√çAS DE KEYWORDS PARA TESIS
# ====================
KEYWORD_CATEGORIES = {
    "Accidente Cerebrovascular": ["accidente cerebrovascular", "acv", "ictus", "stroke"],
    "Alzheimer": ["alzheimer", "demencia", "enfermedad neurodegenerativa"],
    "Arritmias": [
        "arritmia", "fibrilaci√≥n auricular", "fa", "flutter auricular",
        "taquicardia ventricular", "tv", "fibrilaci√≥n ventricular", "fv",
        "bradicardia", "bloqueo auriculoventricular", "s√≠ndrome de brugada",
        "s√≠ndrome de qt largo", "marcapasos", "desfibrilador autom√°tico"
    ],
    "Bioinform√°tica": ["bioinform√°tica", "gen√≥mica computacional", "an√°lisis de secuencias", "biolog√≠a de sistemas"],
    "Bioqu√≠mica": ["bioqu√≠mica", "metabolismo", "enzimas", "rutas metab√≥licas"],
    "Biolog√≠a Molecular": ["adn", "arn", "transcripci√≥n", "replicaci√≥n"],
    "Biomarcadores Card√≠acos": [
        "troponina", "nt-probnp", "bnp", "ck-mb", "lactato deshidrogenasa",
        "mioglobina", "p√©ptidos natriur√©ticos"
    ],
    "Biotecnolog√≠a": ["biotecnolog√≠a", "terapia g√©nica", "crispr", "organismos modificados gen√©ticamente"],
    "C√°ncer de Mama": ["c√°ncer de mama", "tumor mamario", "neoplasia mamaria"],
    "Cardiolog√≠a Pedi√°trica": [
        "cardiopat√≠a cong√©nita", "comunicaci√≥n interauricular", "cia",
        "comunicaci√≥n interventricular", "civ", "tetralog√≠a de fallot",
        "transposici√≥n grandes vasos", "ductus arterioso persistente"
    ],
    "Cardiomiopat√≠as": [
        "cardiomiopat√≠a", "miocardiopat√≠a", "cardiomiopat√≠a hipertr√≥fica", "hcm",
        "cardiomiopat√≠a dilatada", "dcm", "cardiomiopat√≠a restrictiva",
        "displasia arritmog√©nica", "miocardiopat√≠a no compactada", "amiloidosis card√≠aca"
    ],
    "Endocrinolog√≠a": ["diabetes", "tiroides", "hormonas", "metabolismo"],
    "Enfermedad Vascular Perif√©rica": [
        "enfermedad arterial perif√©rica", "eap", "claudicaci√≥n intermitente",
        "√≠ndice tobillo-brazo", "isquemia cr√≠tica", "arteriopat√≠a obliterante"
    ],
    "Epidemiolog√≠a": ["epidemiolog√≠a", "estudios poblacionales", "incidencia", "prevalencia"],
    "Epilepsia": ["epilepsia", "crisis epil√©ptica", "convulsiones"],
    "Farmacolog√≠a": ["farmacolog√≠a", "f√°rmacos", "dosis-respuesta", "toxicidad"],
    "Gastroenterolog√≠a": ["colon", "h√≠gado", "p√°ncreas", "enfermedad inflamatoria intestinal"],
    "Gen√©tica": ["gen√©tica", "mutaciones", "genoma humano", "s√≠ndromes gen√©ticos"],
    "Hipertensi√≥n y Riesgo Cardiovascular": [
        "hipertensi√≥n arterial", "hta", "hipertensi√≥n pulmonar",
        "crisis hipertensiva", "mapa", "monitorizaci√≥n ambulatoria",
        "riesgo cardiovascular", "score framingham", "ascvd"
    ],
    "Inmunolog√≠a": ["autoinmunidad", "inmunodeficiencia", "alergias", "linfocitos"],
    "Inmunoterapia": ["inmunoterapia", "terapia car-t", "checkpoint inmunol√≥gico"],
    "Insuficiencia Card√≠aca": [
        "insuficiencia card√≠aca", "ic", "fallo card√≠aco", "disfunci√≥n ventricular",
        "icfe", "icfd", "fracci√≥n de eyecci√≥n reducida", "fracci√≥n de eyecci√≥n preservada",
        "nyha clase ii", "nyha clase iii", "edema pulmonar", "congesti√≥n venosa"
    ],
    "Investigaci√≥n Cl√≠nica": ["ensayo cl√≠nico", "randomizado", "estudio de cohorte", "fase iii"],
    "Leucemia": ["leucemia", "leucemias agudas", "leucemia mieloide"],
    "Microbiolog√≠a": ["microbiolog√≠a", "bacterias", "virus", "antimicrobianos"],
    "Nefrolog√≠a": ["insuficiencia renal", "glomerulonefritis", "di√°lisis"],
    "Neumolog√≠a": ["asma", "epoc", "fibrosis pulmonar", "s√≠ndrome de apnea del sue√±o"],
    "Neurociencia": ["neurociencia", "plasticidad neuronal", "sinapsis", "neurodegeneraci√≥n"],
    "Oncolog√≠a Molecular": ["oncolog√≠a molecular", "mutaciones tumorales", "biomarcadores c√°ncer"],
    "Procedimientos Cardiol√≥gicos": [
        "cateterismo card√≠aco", "angioplastia", "stent coronario",
        "bypass coronario", "cabg", "ecocardiograma", "eco stress",
        "resonancia card√≠aca", "prueba de esfuerzo", "holter"
    ],
    "S√≠ndrome Coronario Agudo": [
        "s√≠ndrome coronario agudo", "sca", "infarto agudo de miocardio", "iam",
        "iamcest", "iamnest", "angina inestable", "troponina elevada",
        "oclusi√≥n coronaria", "elevaci√≥n st", "depresi√≥n st"
    ],
    "Valvulopat√≠as": [
        "valvulopat√≠a", "estenosis a√≥rtica", "insuficiencia a√≥rtica",
        "stenosis mitral", "insuficiencia mitral", "prolapso mitral",
        "tavi", "taavi", "anillo mitral", "reemplazo valvular"
    ],
}

# ====================
# DEPARTAMENTOS INCICH
# ====================
DEPARTAMENTOS_INCICH = [
    "Bioqu√≠mica",
    "Biolog√≠a Molecular",
    "Biomedicina Cardiovascular",
    "Consulta Externa (Dermatolog√≠a, Endocrinolog√≠a, etc.)",
    "Departamento de Ense√±anza de Enfermer√≠a (DEE)",
    "Endocrinolog√≠a",
    "Farmacolog√≠a",
    "Fisiolog√≠a",
    "Fisiopatolog√≠a Cardio-Renal",
    "Fisiotepatolog√≠a Cardiorenal",
    "Inmunolog√≠a",
    "Instrumentaci√≥n Electromec√°nica",
    "Oficina de Apoyo Sistem√°tico para la Investigaci√≥n Superior (OASIS)",
    "Unidad de Investigaci√≥n UNAM-INC"
]

# ====================
# CONFIGURACI√ìN INICIAL
# ====================
class Config:
    def __init__(self):
        # Configuraci√≥n SFTP
        self.REMOTE_TESIS_FILE = "pro_tesis_total.csv"  # Nombre completo del archivo remoto
        self.TIMEOUT_SECONDS = 30
        
        self.REMOTE = {
            'HOST': st.secrets["sftp"]["host"],
            'USER': st.secrets["sftp"]["user"],
            'PASSWORD': st.secrets["sftp"]["password"],
            'PORT': st.secrets["sftp"]["port"],
            'DIR': st.secrets["sftp"]["dir"]
        }
        
        # Configuraci√≥n de estilo
        self.HIGHLIGHT_COLOR = "#90EE90"
        self.LOGO_PATH = "escudo_COLOR.jpg"

CONFIG = Config()

# ==================
# CLASE SSH MEJORADA
# ==================
class SSHManager:
    MAX_RETRIES = 3
    RETRY_DELAY = 5  # segundos

    @staticmethod
    def get_connection():
        """Establece conexi√≥n SSH segura con reintentos"""
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        
        for attempt in range(SSHManager.MAX_RETRIES):
            try:
                ssh.connect(
                    hostname=CONFIG.REMOTE['HOST'],
                    port=CONFIG.REMOTE['PORT'],
                    username=CONFIG.REMOTE['USER'],
                    password=CONFIG.REMOTE['PASSWORD'],
                    timeout=CONFIG.TIMEOUT_SECONDS
                )
                logging.info(f"Conexi√≥n SSH establecida (intento {attempt + 1})")
                return ssh
            except Exception as e:
                logging.warning(f"Intento {attempt + 1} fallido: {str(e)}")
                if attempt < SSHManager.MAX_RETRIES - 1:
                    time.sleep(SSHManager.RETRY_DELAY)
                else:
                    logging.error("Fallo definitivo al conectar via SSH")
                    st.error(f"Error de conexi√≥n SSH despu√©s de {SSHManager.MAX_RETRIES} intentos: {str(e)}")
                    return None

    @staticmethod
    def verify_file_integrity(local_path, remote_path, sftp):
        """Verifica que el archivo se transfiri√≥ correctamente"""
        try:
            local_size = os.path.getsize(local_path)
            remote_size = sftp.stat(remote_path).st_size
            return local_size == remote_size
        except Exception as e:
            logging.error(f"Error verificando integridad: {str(e)}")
            return False

    @staticmethod
    def download_remote_file(remote_path, local_path):
        """Descarga un archivo con verificaci√≥n de integridad"""
        for attempt in range(SSHManager.MAX_RETRIES):
            ssh = SSHManager.get_connection()
            if not ssh:
                return False
                
            try:
                with ssh.open_sftp() as sftp:
                    try:
                        sftp.stat(remote_path)
                    except FileNotFoundError:
                        logging.error(f"Archivo remoto no encontrado: {remote_path}")
                        return False
                        
                    sftp.get(remote_path, local_path)
                    
                    if SSHManager.verify_file_integrity(local_path, remote_path, sftp):
                        logging.info(f"Archivo descargado correctamente: {remote_path} a {local_path}")
                        return True
                    else:
                        logging.warning(f"Error de integridad en descarga, reintentando... (intento {attempt + 1})")
                        if attempt < SSHManager.MAX_RETRIES - 1:
                            time.sleep(SSHManager.RETRY_DELAY)
                        else:
                            raise Exception("Fallo en verificaci√≥n de integridad despu√©s de m√∫ltiples intentos")
                            
            except Exception as e:
                logging.error(f"Error en descarga (intento {attempt + 1}): {str(e)}")
                if attempt == SSHManager.MAX_RETRIES - 1:
                    st.error(f"Error descargando archivo remoto despu√©s de {SSHManager.MAX_RETRIES} intentos: {str(e)}")
                    return False
                    
            finally:
                ssh.close()

def sync_tesis_file():
    """Sincroniza el archivo tesis_total.csv desde el servidor remoto"""
    try:
        remote_path = os.path.join(CONFIG.REMOTE['DIR'], CONFIG.REMOTE_TESIS_FILE)
        local_path = "tesis_total.csv"
        
        with st.spinner("üîÑ Sincronizando archivo tesis_total.csv desde el servidor..."):
            if SSHManager.download_remote_file(remote_path, local_path):
                st.success("‚úÖ Archivo tesis_total.csv sincronizado correctamente")
                return True
            else:
                st.error("‚ùå No se pudo descargar el archivo tesis_total.csv del servidor")
                return False
    except Exception as e:
        st.error(f"‚ùå Error en sincronizaci√≥n: {str(e)}")
        logging.error(f"Sync Error: {str(e)}")
        return False

def highlight_author(author: str, investigator_name: str) -> str:
    """Resalta el nombre del investigador principal"""
    if investigator_name and investigator_name.lower() == author.lower():
        return f"<span style='background-color: {CONFIG.HIGHLIGHT_COLOR};'>{author}</span>"
    return author

def main():
    st.set_page_config(
        page_title="An√°lisis de Tesis",
        page_icon="üìö",
        layout="wide"
    )
    
    # A√±adir logo en la parte superior
    if Path(CONFIG.LOGO_PATH).exists():
        st.image(CONFIG.LOGO_PATH, width=200)
    
    st.title("An√°lisis de Tesis")
    
    # Sincronizar archivo tesis_total.csv al inicio
    if not sync_tesis_file():
        st.warning("‚ö†Ô∏è Trabajando con copia local de tesis_total.csv debido a problemas de conexi√≥n")
    
    # Verificar si el archivo local existe
    if not Path("tesis_total.csv").exists():
        st.error("No se encontr√≥ el archivo tesis_total.csv")
        return
    
    try:
        # Leer y procesar el archivo con los nuevos campos sni y sii
        df = pd.read_csv("tesis_total.csv")
        
        # Verificar que los campos importantes existen
        required_columns = ['directores', 'titulo_tesis', 'pub_date', 'estado', 'selected_keywords']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.warning(f"El archivo tesis_total.csv no contiene los campos requeridos: {', '.join(missing_columns)}")
            return
        
        # Convertir y validar fechas
        df['pub_date'] = pd.to_datetime(df['pub_date'], errors='coerce')
        df = df[(df['estado'] == 'A') & (df['pub_date'].notna())]
        
        if df.empty:
            st.warning("No hay tesis v√°lidas para analizar")
            return
        
        st.success(f"Datos cargados correctamente. Registros activos: {len(df)}")
        
        # Obtener rangos de fechas disponibles
        min_date = df['pub_date'].min()
        max_date = df['pub_date'].max()
        
        # Selector de rango mes-a√±o con ayuda
        st.header("üìÖ Selecci√≥n de Periodo")
        col1, col2 = st.columns(2)
        
        with col1:
            start_year = st.selectbox("A√±o inicio", 
                                   range(min_date.year, max_date.year+1),
                                   index=0,
                                   help="Selecciona el a√±o inicial para el an√°lisis.")
            start_month = st.selectbox("Mes inicio", 
                                    range(1, 13), 
                                    index=min_date.month-1,
                                    format_func=lambda x: datetime(1900, x, 1).strftime('%B'),
                                    help="Selecciona el mes inicial para el an√°lisis.")
        
        with col2:
            end_year = st.selectbox("A√±o t√©rmino", 
                                  range(min_date.year, max_date.year+1),
                                  index=len(range(min_date.year, max_date.year+1))-1,
                                  help="Selecciona el a√±o final para el an√°lisis.")
            end_month = st.selectbox("Mes t√©rmino", 
                                   range(1, 13), 
                                   index=max_date.month-1,
                                   format_func=lambda x: datetime(1900, x, 1).strftime('%B'),
                                   help="Selecciona el mes final para el an√°lisis.")
        
        # Calcular fechas de inicio y fin
        start_day = 1
        end_day = calendar.monthrange(end_year, end_month)[1]
        
        date_start = datetime(start_year, start_month, start_day)
        date_end = datetime(end_year, end_month, end_day)
        
        # Filtrar dataframe
        filtered_df = df[(df['pub_date'] >= pd.to_datetime(date_start)) & 
                       (df['pub_date'] <= pd.to_datetime(date_end))]
        
        # Obtener tesis √∫nicas para estad√≠sticas precisas
        unique_tesis = filtered_df.drop_duplicates(subset=['titulo_tesis'])
        
        st.markdown(f"**Periodo seleccionado:** {date_start.strftime('%d/%m/%Y')} - {date_end.strftime('%d/%m/%Y')}",
                   help="Rango de fechas seleccionado para el an√°lisis.")
        st.markdown(f"**Registros encontrados:** {len(filtered_df)}",
                   help="Total de registros en el periodo, incluyendo posibles duplicados de la misma tesis.")
        st.markdown(f"**Tesis √∫nicas:** {len(unique_tesis)}",
                   help="Cantidad de tesis distintas, eliminando duplicados.")
        
        if len(filtered_df) != len(unique_tesis):
            st.warning(f"‚ö†Ô∏è **Nota:** Se detectaron {len(filtered_df) - len(unique_tesis)} registros duplicados de la misma tesis.")
        
        if filtered_df.empty:
            st.warning("No hay tesis en el periodo seleccionado")
            return
        
        # An√°lisis consolidado en tablas
        st.header("üìä Estad√≠sticas Consolidadas",
                help="M√©tricas generales basadas en los filtros aplicados.")
        
        # Tabla 1: Productividad por director (TESIS √öNICAS)
        st.subheader("üîç Productividad por Director",
                   help="Muestra cu√°ntas tesis √∫nicas ha dirigido cada investigador.")
        
        # Crear dataframe con informaci√≥n de directores
        director_stats = filtered_df.groupby('directores').agg(
            Tesis_Unicas=('titulo_tesis', lambda x: len(set(x)))
        ).reset_index()
        
        director_stats = director_stats.sort_values('Tesis_Unicas', ascending=False)
        director_stats.columns = ['Director', 'Tesis √∫nicas']
        
        # A√±adir fila de totales
        total_row = pd.DataFrame({
            'Director': ['TOTAL'],
            'Tesis √∫nicas': [director_stats['Tesis √∫nicas'].sum()]
        })
        director_stats = pd.concat([director_stats.head(10), total_row], ignore_index=True)
        
        # Mostrar tabla con enlaces clickeables
        for index, row in director_stats.iterrows():
            if row['Director'] != 'TOTAL':
                # Crear un expander para cada director
                with st.expander(f"{row['Director']} - {row['Tesis √∫nicas']} tesis"):
                    # Filtrar las tesis del director
                    director_tesis = filtered_df[filtered_df['directores'] == row['Director']]
                    unique_tesis_director = director_tesis.drop_duplicates(subset=['titulo_tesis'])
                    
                    # Mostrar las tesis (incluyendo los nuevos campos si existen)
                    display_columns = ['titulo_tesis', 'tipo_tesis', 'pub_date', 'estudiante']
                    if 'sni' in unique_tesis_director.columns and 'sii' in unique_tesis_director.columns:
                        display_columns.extend(['sni', 'sii'])
                    
                    st.write(f"Tesis dirigidas por {row['Director']}:")
                    st.dataframe(unique_tesis_director[display_columns])
                    
                    # Opci√≥n para descargar en CSV
                    csv = unique_tesis_director.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Descargar producci√≥n de tesis en CSV",
                        data=csv,
                        file_name=f"tesis_{row['Director'].replace(' ', '_')}.csv",
                        mime='text/csv',
                        key=f"download_{index}"
                    )
        
        # Tabla 2: Tipos de tesis m√°s comunes (TESIS √öNICAS)
        st.subheader("üéì Tipos de Tesis",
                   help="Distribuci√≥n de los tipos de tesis.")
        tipo_stats = unique_tesis['tipo_tesis'].value_counts().reset_index()
        tipo_stats.columns = ['Tipo de tesis', 'Tesis √∫nicas']
        
        # A√±adir fila de totales
        total_row = pd.DataFrame({
            'Tipo de tesis': ['TOTAL'],
            'Tesis √∫nicas': [tipo_stats['Tesis √∫nicas'].sum()]
        })
        tipo_stats = pd.concat([tipo_stats, total_row], ignore_index=True)
        st.dataframe(tipo_stats, hide_index=True)
        
        # Tabla 3: Enfoques m√°s frecuentes (TESIS √öNICAS)
        st.subheader("üß™ Enfoques m√°s Frecuentes",
                   help="Palabras clave m√°s utilizadas en las tesis, indicando las √°reas de investigaci√≥n predominantes.")
        try:
            all_keywords = []
            for keywords in unique_tesis['selected_keywords']:
                if pd.notna(keywords):
                    # Limpiar y procesar las palabras clave
                    cleaned = str(keywords).strip("[]'").replace("'", "").split(", ")
                    all_keywords.extend([k.strip() for k in cleaned if k.strip()])
            
            keyword_stats = pd.Series(all_keywords).value_counts().reset_index()
            keyword_stats.columns = ['Enfoque', 'Frecuencia']
            
            # A√±adir fila de totales
            total_row = pd.DataFrame({
                'Enfoque': ['TOTAL'],
                'Frecuencia': [keyword_stats['Frecuencia'].sum()]
            })
            keyword_stats = pd.concat([keyword_stats.head(10), total_row], ignore_index=True)
            st.dataframe(keyword_stats, hide_index=True)
        except Exception as e:
            st.warning(f"No se pudieron procesar las palabras clave: {str(e)}")
        
        # Tabla 4: Distribuci√≥n por departamentos (TESIS √öNICAS)
        if 'departamento' in unique_tesis.columns:
            st.subheader("üèõÔ∏è Distribuci√≥n por Departamento",
                       help="Clasificaci√≥n de tesis seg√∫n el departamento de adscripci√≥n del director.")
            depto_stats = unique_tesis['departamento'].value_counts().reset_index()
            depto_stats.columns = ['Departamento', 'Tesis √∫nicas']
            
            # A√±adir fila de totales
            total_row = pd.DataFrame({
                'Departamento': ['TOTAL'],
                'Tesis √∫nicas': [depto_stats['Tesis √∫nicas'].sum()]
            })
            depto_stats = pd.concat([depto_stats, total_row], ignore_index=True)
            st.dataframe(depto_stats, hide_index=True)
        else:
            st.warning("El campo 'departamento' no est√° disponible en los datos")
        
        # Tabla 5: Distribuci√≥n temporal (TESIS √öNICAS)
        st.subheader("üï∞Ô∏è Distribuci√≥n Mensual",
                    help="Evoluci√≥n mensual de la producci√≥n de tesis en el periodo seleccionado.")

        # Convertir a formato "YYYY-MM" - CORRECCI√ìN: usar astype(str) en lugar de astipestr
        time_stats = unique_tesis['pub_date'].dt.to_period('M').astype(str).value_counts().sort_index().reset_index()
        time_stats.columns = ['Mes-A√±o', 'Tesis √∫nicas']

        # A√±adir fila de totales
        total_row = pd.DataFrame({
            'Mes-A√±o': ['TOTAL'],
            'Tesis √∫nicas': [time_stats['Tesis √∫nicas'].sum()]
        })
        time_stats = pd.concat([time_stats, total_row], ignore_index=True)
        st.dataframe(time_stats, hide_index=True)
        
        # Tabla 6: Distribuci√≥n por nivel SNI (TESIS √öNICAS)
        if 'sni' in unique_tesis.columns:
            st.subheader("üìä Distribuci√≥n por Nivel SNI",
                        help="Clasificaci√≥n de tesis seg√∫n el nivel del Sistema Nacional de Investigadores (SNI) de los directores.")
            sni_stats = unique_tesis['sni'].value_counts().reset_index()
            sni_stats.columns = ['Nivel SNI', 'Tesis √∫nicas']
            
            # A√±adir fila de totales
            total_row = pd.DataFrame({
                'Nivel SNI': ['TOTAL'],
                'Tesis √∫nicas': [sni_stats['Tesis √∫nicas'].sum()]
            })
            sni_stats = pd.concat([sni_stats, total_row], ignore_index=True)
            st.dataframe(sni_stats, hide_index=True)
        else:
            st.warning("El campo 'sni' no est√° disponible en los datos")
        
        # Tabla 7: Distribuci√≥n por nivel SII (TESIS √öNICAS)
        if 'sii' in unique_tesis.columns:
            st.subheader("üìà Distribuci√≥n por Nivel SII",
                        help="Clasificaci√≥n de tesis seg√∫n el nivel del Sistema Institucional de Investigaci√≥n (SII) de los directores.")
            sii_stats = unique_tesis['sii'].value_counts().reset_index()
            sii_stats.columns = ['Nivel SII', 'Tesis √∫nicas']
            
            # A√±adir fila de totales
            total_row = pd.DataFrame({
                'Nivel SII': ['TOTAL'],
                'Tesis √∫nicas': [sii_stats['Tesis √∫nicas'].sum()]
            })
            sii_stats = pd.concat([sii_stats, total_row], ignore_index=True)
            st.dataframe(sii_stats, hide_index=True)
        else:
            st.warning("El campo 'sii' no est√° disponible en los datos")
        
        # Tabla 8: Distribuci√≥n por idioma (TESIS √öNICAS)
        if 'idioma' in unique_tesis.columns:
            st.subheader("üåê Distribuci√≥n por Idioma",
                        help="Idiomas en los que est√°n escritas las tesis.")
            idioma_stats = unique_tesis['idioma'].value_counts().reset_index()
            idioma_stats.columns = ['Idioma', 'Tesis √∫nicas']
            
            # A√±adir fila de totales
            total_row = pd.DataFrame({
                'Idioma': ['TOTAL'],
                'Tesis √∫nicas': [idioma_stats['Tesis √∫nicas'].sum()]
            })
            idioma_stats = pd.concat([idioma_stats, total_row], ignore_index=True)
            st.dataframe(idioma_stats, hide_index=True)
        else:
            st.warning("El campo 'idioma' no est√° disponible en los datos")
            
        # Tabla 9: Estudiantes con m√°s tesis (TESIS √öNICAS)
        st.subheader("üë®‚Äçüéì Estudiantes con m√°s tesis",
                    help="Listado de estudiantes ordenados por cantidad de tesis realizadas.")
        estudiante_stats = unique_tesis['estudiante'].value_counts().reset_index()
        estudiante_stats.columns = ['Estudiante', 'Tesis √∫nicas']
        
        # A√±adir fila de totales
        total_row = pd.DataFrame({
            'Estudiante': ['TOTAL'],
            'Tesis √∫nicas': [estudiante_stats['Tesis √∫nicas'].sum()]
        })
        estudiante_stats = pd.concat([estudiante_stats.head(10), total_row], ignore_index=True)
        st.dataframe(estudiante_stats, hide_index=True)
        
        # ==========================================
        # SECCI√ìN: DESCARGAR ARCHIVO COMPLETO
        # ==========================================
        st.header("üì• Descargar Datos Completos")
        
        # Opci√≥n para descargar el archivo pro_tesis_total.csv
        if Path("tesis_total.csv").exists():
            with open("tesis_total.csv", "rb") as file:
                btn = st.download_button(
                    label="Descargar archivo pro_tesis_total.csv completo",
                    data=file,
                    file_name="pro_tesis_total.csv",
                    mime="text/csv",
                    help="Descarga el archivo CSV completo con todos los datos de tesis"
                )
            if btn:
                st.success("Descarga iniciada")
        else:
            st.warning("El archivo tesis_total.csv no est√° disponible para descargar")
        
    except Exception as e:
        st.error(f"Error al procesar el archivo: {str(e)}")
        logging.error(f"Error en main: {str(e)}")

if __name__ == "__main__":
    main()
